<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<link rel="icon" type="image/png" href="new-images/duke.png">
    <title>Yanming Xiu (修彦名)</title>

    <meta name="author" content="Yanming Xiu | 修彦名">
    <meta name="viewport" content="width=device-width, initial-scale=1">
<!--     <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon"> -->
    <link rel="stylesheet" type="text/css" href="stylesheet.css">


    <style>
      .content-divider::before {
        content: '\2022'; /* Unicode character for a black dot */
        font-size: 24px;
        padding: 0 10px;
        color: black;
      }
    </style>

    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  <b>Yanming Xiu (修彦名)</b>
                </p>
                <p>
                  Greetings! I am currently a 3rd year Ph.D. candidate at <a href="https://maria.gorlatova.com">Intelligent Interactive Internet of Things (I^3T) Lab </a>, <a href="https://ece.duke.edu/">Department of Electrical and Computer Engineering, Duke University</a> in Durham, NC, where I work on computer vision, deep learning and medical imaging. My Advisor is <a href="https://maria.gorlatova.com/bio/">Dr. Maria Gorlatova</a>.
                </p>
                <p>
                  Prior to coming to Duke, I earned my B.Eng. in Automation and a honor undergraduate degree at <a href:"https://www.zju.edu.cn/english/"> Zhejiang University</a> in 2022. I also worked as a research assistant at the <a href:"https://www.hku.hk/">University of Hong Kong</a> in 2021.
                </p>
                <p>
                  
                </p>
                <p style="text-align:center">
                  <a href="new-data/YanmingXiuCV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="new-data/email.txt">Email</a> &nbsp;/&nbsp;
                  <a href="https://github.com/YM-Xiu">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/yanmingxiu">Linkedin</a> &nbsp;/&nbsp;
		<a href="https://scholar.google.com/citations?user=w628QKEAAAAJ&hl=en">Google Scholar</a>
<!--                   <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
<!--                   <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp;/&nbsp; -->
<!--                   <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                  
                  
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="new-images/yanming_new.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="new-images/yanming_new.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2><b>Research Interests</b></h2>
                <p>
                  I'm interested in machine learning and its application in computer vision, especially Augmented Reality (AR) and Virtual Reality (VR). Currently I am also interested in generative AI and its application.
                </p>
                  My current research is mainly focused on: (1) addressing user safety issues in AR experiences by modeling and detecting detrimental virtual content; (2) assessing virtual content quality by using automated systems leveraging generative AI.
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2><b>Experiences</b></h2>
                <p>
                  <ul>
		<li>
                      Dec. 2023 - Now: Research Assistant, <a href="https://ece.duke.edu/">Department of Electrical and Computer Engineering, Duke University</a>
                      <p>
                        Advisor: <a href="https://maria.gorlatova.com/bio/">Dr. Maria Gorlatova</a>
                      </p>
                    </li><br>
                    <li>
                      Aug. 2022 - Nov. 2023: Research Assistant, <a href="https://psychiatry.duke.edu/">Department of Psychiatry and Behavioral Science, Duke University</a>
                      <p>
                        Advisor: <a href="https://med.emory.edu/directory/profile/?u=YWAN303">Dr. Yun Wang</a>, <a href="https://psychiatry.duke.edu/profile/jonathan-posner">Prof. Jonathan Posner</a>
                      </p>
                    </li><br>
                    <li>
                      Jul. 2021 - Dec. 2021: Research Assistant, <a href="https://www.cs.hku.hk/">Department of Computer Science, University of Hong Kong </a>
                      <p>
                        Advisor: <a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html"> Prof. Wenping Wang</a>
                      </p>
                    </li><br>
                    <li>
                      Mar. 2020 - May. 2021: Research Assistant, College of Control Science and Engineering, Zhejiang University
                      <p>
                        Advisor: <a href="https://person.zju.edu.cn/en/jmchen"> Prof. Jiming Chen</a>
                      </p>
                    </li>
                  </ul>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2><b>Education</b></h2>
                <p>
                  
                  <ul>
                  <li>
                         Aug. 2022 - Now: Ph.D. Student, Department of Electrical and Computer Engineering, Duke University
                          <p>
                          GPA: 3.86/4.00
                          </p>
                        
                  </li><br>
                    <li>
                      Aug. 2018 - Jun. 2022: B.Eng in Automation, <a href="http://www.cse.zju.edu.cn/cseenglish/main.htm">College of Control Science and Engineering, Zhejiang University </a>
                      <p>
                        GPA: 3.85/4.00
                      </p>
                  </li><br>
                  <li>
                      Aug. 2018 - Jun. 2022: Honors Degree, <a href="http://ckc.zju.edu.cn/ckcen/">Chu-Kochen Honors College, Zhejiang University </a>
                  </li><br>
                  </u>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2><b>Honors</b></h2>
                <p>
                  <ul>
                    <li>
                      Jun. 2022: Outstanding Undergraduate Graduates, Zhejiang University (Top 10%)
                    </li><br>
                    <li>
                      Oct. 2021: First Tier Scholaship for Academic Excellence, Zhejiang University (Top 5%)
                    </li><br>
                  </ul>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


		  
<!-- 	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2><b>Publications (*Equal Contributions)</b></h2>
            </td>
          </tr>
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	<tr>
        <papertitle> ViDDAR: Vision Language Model-Based Task-Detrimental Content Detection for Augmented Reality </papertitle>
		<p>
		<strong>Yanming Xiu</strong>, Tim Scargill, Maria Gorlatova.
		</p>
		    <p>
			   IEEE Transactions on Visualization and Computer Graphics (TVCG), 2025 
		    </p>
                <br>
							<a href="https://www.computer.org/csdl/journal/tg/2025/05/10924575/251sSyPifN6"> Paper </a> / <a href="https://youtu.be/7hboev8wvio">Video</a>
              <p>
              	Our work explores how virtual content in AR can negatively impact user tasks when poorly placed or designed. 
		      We define two attack types: obstruction and information manipulation, and introduce ViDDAR, a system that uses Vision Language Models to detect these issues in real time. 
		      ViDDAR achieves high accuracy in detecting harmful content while maintaining low latency, helping ensure safer and more effective AR experiences.
	      </p>
            </td>
          </tr>

          </tbody></table> -->

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2><b>Publications (*Equal Contributions)</b></h2>
                <p>
                  
                  <ul>
                  <li>
                         ViDDAR: Vision Language Model-Based Task-Detrimental Content Detection for Augmented Reality
                          <p>
                          <strong>Yanming Xiu</strong>, Tim Scargill, Maria Gorlatova.
                          </p>
			  <p>
				IEEE Transactions on Visualization and Computer Graphics (TVCG), 2025  
			  </p>
			  <p>
			<a href="https://www.computer.org/csdl/journal/tg/2025/05/10924575/251sSyPifN6"> Paper </a> / <a href="https://youtu.be/7hboev8wvio">Video</a>  
			  </p>
                        
                  </li><br>
                    <li>
                      Aug. 2018 - Jun. 2022: B.Eng in Automation, <a href="http://www.cse.zju.edu.cn/cseenglish/main.htm">College of Control Science and Engineering, Zhejiang University </a>
                      <p>
                        GPA: 3.85/4.00
                      </p>
                  </li><br>
                  <li>
                      Aug. 2018 - Jun. 2022: Honors Degree, <a href="http://ckc.zju.edu.cn/ckcen/">Chu-Kochen Honors College, Zhejiang University </a>
                  </li><br>
                  </u>
                </p>
              </td>
            </tr>
          </tbody></table>



		  

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2><b>Other Projects</b></h2>
              <p>
                Some of my previous projects are listed here:
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr onmouseout="foldbot_stop()" onmouseover="foldbot_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='foldbot_image'><video  width=100% height=100% muted autoplay loop>
                <source src="new-images/foldbot_clipped.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='new-images/foldbot_cover.jpg' width="160">
              </div>
              <script type="text/javascript">
                function foldbot_start() {
                  document.getElementById('foldbot_image').style.opacity = "1";
                }

                function foldbot_stop() {
                  document.getElementById('foldbot_image').style.opacity = "0";
                }
                foldbot_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://www.youtube.com/watch?v=Ee9dMaSq948">
                <papertitle>Clothes Folding Robot</papertitle>
              </a>
                <br>
							<a href="https://www.youtube.com/watch?v=Ee9dMaSq948">Video</a>
              <p></p>
              <p>This is a joint project co-advised by Prof. Wenping Wang from HKU and <a href="https://person.zju.edu.cn/en/0091102">Prof. Yiping Feng</a> from ZJU.
		The project include 3 parts: 1) clothes landmark detection through HRNet, 2) Robotic arm path planning and 3) Overall system construction. The camera takes an image of clothes and pass it to my fork version of
		      <a href="https://github.com/svip-lab/HRNet-for-Fashion-Landmark-Estimation.PyTorch">HRNet</a> . Then the HRNet predict the key points of the clothes and pass them to robot control script.
		      Finally, the arm execute the folding process.
	      </p>
            </td>
          </tr>

          </tbody></table>
		  
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	<tr onmouseout="bellbot_stop()" onmouseover="bellbot_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='bellbot_image'><video  width=100% height=100% muted autoplay loop>
                <source src="new-images/bellbot_clipped3.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='new-images/bellbot_cover.jpg' width="160">
              </div>
              <script type="text/javascript">
                function bellbot_start() {
                  document.getElementById('bellbot_image').style.opacity = "1";
                }

                function bellbot_stop() {
                  document.getElementById('bellbot_image').style.opacity = "0";
                }
                bellbot_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://www.youtube.com/watch?v=sG8bIiiRh5w">
                <papertitle>Bell Hitting Robot</papertitle>
              </a>
                <br>
							<a href="https://www.youtube.com/watch?v=sG8bIiiRh5w">Video</a>
              <p></p>
              <p>This is a competition held by ZJU CSE. The participants are required to control the robot arm and hit the bells for as much times as possible within 1 minute, while obstacle avoidance is also required.
		I loaded the robot model in Gazebo, implemented the torque control algorithm and tested it in real-world robot.
	      </p>
            </td>
          </tr>

          </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	<tr>
	      <td style="padding:20px;width:25%;vertical-align:middle">
	        <div class="one">
	          <div class="two" id='bellbot_image'>
	            <img src='new-images/RFID.jpg' width="160">
	          </div>
	        </div>
	      </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://www.youtube.com/watch?v=KliKUNSbHa0">
                <papertitle> Chipless RFID Tag Detection </papertitle>
              </a>
                <br>
							<a href="https://www.youtube.com/watch?v=KliKUNSbHa0">Video</a> / <a href="new-data/RFID.pptx">Slides (in Chinese)</a>
              <p></p>
              <p>This is a training program in 2020, in which I designed a new type of chipless RFID tag so that the production cost of tags can be reduced. 
		      The tag can be correctly detected by the RFID reader at around 5-80 cm, which are common detection distances for warehouse logistics tasks.
	      </p>
            </td>
          </tr>

          </tbody></table>

	          <footer class="footer">
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                    <td width=30%>
                        <br>
                        <p align="left">
                            <font size="2">
                               Last updated on May. 2025
                            </font>
                        </p>
                    </td>

                    <td width=40% align="center" hidden="hidden">
<!--                       <a href="https://clustrmaps.com/site/1bl80"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=p50vKcM-nrOZmNqIPVxMBYv8gETkGPaJxWjM23aTZQg&cl=ffffff" /></a> -->
			    <a href="https://clustrmaps.com/site/1bx20"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=Zq2A_XW0RqFrN2xh8xZ6sjz09viht1OrUSHRcvxPiaU&cl=ffffff" /></a>
                    </td>
                    <td width=30%>
                        <br>
                        <p align="right">
                            <font size="2">
                                Website forked from <a href="https://jonbarron.info/">Jon Barron</a>
                            </font>
                        </p>
                    </td>
                </tr>
            </table>
        </footer>

